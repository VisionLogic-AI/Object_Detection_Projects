{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Age Prediction Using Brain Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoP41G1vJsyF4hYo9N8MaD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VisionLogic-AI/Object_Detection_Projects/blob/branch_1/Age_Prediction_Using_Brain_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_XQVEQcx2qN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "986a5963-7baf-425b-9e29-9057ed2dd9eb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#use tensorflow 1.x backend\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWBs-Gd7MhGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ensure that we are using tensorflow 1.x and not 2.x\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cLliZoky4SU",
        "colab_type": "text"
      },
      "source": [
        "#Next, we import the necessary modules or libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3aQQN5QwJ33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "90da5a1c-b8d8-46f5-ce2d-e4692773f715"
      },
      "source": [
        "#clone into the dataset hostged on Gtuhub (or upload from downloads)\n",
        "!wget -nc https://raw.githubusercontent.com/saigerutherford/anatomically_defined_CNNs/master/requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-16 22:32:08--  https://raw.githubusercontent.com/saigerutherford/anatomically_defined_CNNs/master/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1317 (1.3K) [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]   1.29K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-16 22:32:09 (82.7 MB/s) - ‘requirements.txt’ saved [1317/1317]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIn6O4M0LP1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3172f96-9c70-4ec8-ef68-1e70f40ab1f1"
      },
      "source": [
        "#install requirements.txt files \n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting absl-py==0.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 6.3MB/s \n",
            "\u001b[?25hCollecting astor==0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
            "Collecting attrs==19.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/23/96/d828354fa2dbdf216eaa7b7de0db692f12c234f7ef888cc14980ef40d1d2/attrs-19.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: backcall==0.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.1.0)\n",
            "Collecting bleach==3.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/bc/9c2bbd8bff5f393e3373687109117a061db4c8ccdf6b5c70b1f8834bd67a/bleach-3.1.4-py2.py3-none-any.whl (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.10.0)\n",
            "Collecting decorator==4.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: defusedxml==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.6.0)\n",
            "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.3)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting grpcio==1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/83/18f374294bf34128a448ee2fae37651f943b0b5fa473b5b3aff262c15bf8/grpcio-1.21.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 49.5MB/s \n",
            "\u001b[?25hCollecting h5py==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 55.6MB/s \n",
            "\u001b[?25hCollecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 56.9MB/s \n",
            "\u001b[?25hCollecting ipykernel==5.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/35/dd97fbb48d4e6b5ae97307497e31e46691adc2feedb6279d29fc1c8ad9c1/ipykernel-5.1.1-py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 58.6MB/s \n",
            "\u001b[?25hCollecting ipython==7.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/2e/41dce4ed129057e05a555a7f9629aa2d5f81fdcd4d16568bc24b75a1d2c9/ipython-7.5.0-py3-none-any.whl (770kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (0.2.0)\n",
            "Collecting ipywidgets==7.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/9a/a008c7b1183fac9e52066d80a379b3c64eab535bd9d86cdc29a0b766fd82/ipywidgets-7.4.2-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 55.5MB/s \n",
            "\u001b[?25hCollecting jedi==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/2b/1f188901be099d52d7b06f4d3b7cb9f8f09692c50697b139eaf6fa2928d8/jedi-0.13.3-py2.py3-none-any.whl (178kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 59.7MB/s \n",
            "\u001b[?25hCollecting Jinja2==2.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/e7/fd8b501e7a6dfe492a433deb7b9d833d39ca74916fa8bc63dd1a4947a671/Jinja2-2.10.1-py2.py3-none-any.whl (124kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 59.6MB/s \n",
            "\u001b[?25hCollecting joblib==0.13.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 58.4MB/s \n",
            "\u001b[?25hCollecting jsonschema==3.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/69/df679dfbdd051568b53c38ec8152a3ab6bc533434fc7ed11ab034bf5e82f/jsonschema-3.0.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 22)) (1.0.0)\n",
            "Collecting jupyter-client==5.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/c3/3043fe9ffd140d03c9d091a056794ccdc427c56ec19b8eea74f9ea0a498f/jupyter_client-5.2.4-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 15.2MB/s \n",
            "\u001b[?25hCollecting jupyter-console==6.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/ee/6374ae8c21b7d0847f9c3722dcdfac986b8e54fa9ad9ea66e1eb6320d2b8/jupyter_console-6.0.0-py2.py3-none-any.whl\n",
            "Collecting jupyter-core==4.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/44/065d2d7bae7bebc06f1dd70d23c36da8c50c0f08b4236716743d706762a8/jupyter_core-4.4.0-py2.py3-none-any.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 64.7MB/s \n",
            "\u001b[?25hCollecting jupyterlab==0.35.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/7f/18b4ecfa055243f1eccdb1d7a1cdc0ae529f3df4c1098cee442ad177511a/jupyterlab-0.35.6-py3-none-any.whl (14.8MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8MB 201kB/s \n",
            "\u001b[?25hCollecting jupyterlab-server==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/78/77/e8a9c300afbe24aa46abaf1091d9e7b82328559e99cf2d601e858bcb3e1a/jupyterlab_server-0.2.0-py3-none-any.whl\n",
            "Collecting Keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 29)) (1.0.8)\n",
            "Collecting Keras-Preprocessing==1.0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.4MB/s \n",
            "\u001b[?25hCollecting kiwisolver==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 813kB/s \n",
            "\u001b[?25hCollecting Markdown==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 33)) (1.1.1)\n",
            "Collecting matplotlib==3.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0MB)\n",
            "\u001b[K     |████████████████████████████████| 13.0MB 257kB/s \n",
            "\u001b[?25hRequirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 35)) (0.8.4)\n",
            "Collecting mock==3.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Collecting nbconvert==5.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/e7/f46c9d65f149271e47fca6ab084ef5c6e4cb1870f4c5cce6690feac55231/nbconvert-5.5.0-py2.py3-none-any.whl (447kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 59.9MB/s \n",
            "\u001b[?25hCollecting nbformat==4.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/27/9a654d2b6cc1eaa517d1c5a4405166c7f6d72f04f6e7eea41855fe808a46/nbformat-4.4.0-py2.py3-none-any.whl (155kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 64.5MB/s \n",
            "\u001b[?25hCollecting nibabel==2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/30/fbed62172920c3fd050b6483541546a87c5e735f4a0ef03f08bb150680b4/nibabel-2.4.1-py2.py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 48.5MB/s \n",
            "\u001b[?25hCollecting nilearn==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/65/ba76e7cd544dafc28960e60b099d6f906a2096034c560158beaf2ff299bc/nilearn-0.5.2-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 44.7MB/s \n",
            "\u001b[?25hCollecting notebook==5.7.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/36/89ebfffc9dd8c8dbd81c1ffb53e3d4233ee666414c143959477cb07cc5f5/notebook-5.7.8-py2.py3-none-any.whl (9.0MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0MB 18.4MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 212kB/s \n",
            "\u001b[?25hCollecting pandas==0.24.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandocfilters==1.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 44)) (1.4.2)\n",
            "Collecting parso==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/bd/e2f4753c5fa93932899243b4299011a757ac212e9bc8ddf062f38df4e78b/parso-0.4.0-py2.py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 15.5MB/s \n",
            "\u001b[?25hCollecting pexpect==4.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 47)) (0.7.5)\n",
            "Collecting prometheus-client==0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/bd/b42db3ec90ffc6be805aad09c1cea4bb13a620d0cd4b21aaa44d13541d71/prometheus_client-0.6.0.tar.gz\n",
            "Collecting prompt-toolkit==2.0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 57.3MB/s \n",
            "\u001b[?25hCollecting protobuf==3.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/fb/29de8d08967f0cce1bb10b39846d836b0f3bf6776ddc36aed7c73498ca7e/protobuf-3.8.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: ptyprocess==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 51)) (0.6.0)\n",
            "Collecting pydot==1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
            "Collecting Pygments==2.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/73/1dfa428150e3ccb0fa3e68db406e5be48698f2a979ccbcec795f28f44048/Pygments-2.4.2-py2.py3-none-any.whl (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.1MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[?25hCollecting pyrsistent==0.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/0b/f514e76b4e074386b60cfc6c8c2d75ca615b81e415417ccf3fac80ae0bf6/pyrsistent-0.15.2.tar.gz (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 60.9MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 52.9MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 65.3MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 65.0MB/s \n",
            "\u001b[?25hCollecting pyzmq==18.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/04/f6f0fa20b698b29c6e6b1d6b4b575c12607b0abf61810aab1df4099988c6/pyzmq-18.0.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.7MB/s \n",
            "\u001b[?25hCollecting qtconsole==4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/0b/efb5a694b6922bb85c35e4f1db6197daae23c764dd384023fc9517d79e26/qtconsole-4.5.1-py2.py3-none-any.whl (118kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 67.1MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 50.9MB/s \n",
            "\u001b[?25hCollecting scipy==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Send2Trash==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 63)) (1.5.0)\n",
            "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 64)) (1.12.0)\n",
            "Collecting tensorboard==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 51.0MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 62.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 68)) (1.1.0)\n",
            "Collecting terminado==0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/56/80ea7fa66565fa75ae21ce0c16bc90067530e5d15e48854afcc86585a391/terminado-0.8.2-py2.py3-none-any.whl\n",
            "Collecting testpath==0.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/a4/162f9ebb6489421fe46dcca2ae420369edfee4b563c668d93cb4605d12ba/testpath-0.4.2-py2.py3-none-any.whl (163kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 60.9MB/s \n",
            "\u001b[?25hCollecting tornado==6.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/3f/5f89d99fca3c0100c8cede4f53f660b126d39e0d6a1e943e95cc3ed386fb/tornado-6.0.2.tar.gz (481kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 65.7MB/s \n",
            "\u001b[?25hCollecting traitlets==4.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/d6/abcb22de61d78e2fc3959c964628a5771e47e7cc60d53e9342e21ed6cc9a/traitlets-4.3.2-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.1MB/s \n",
            "\u001b[?25hCollecting wcwidth==0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 74)) (0.5.1)\n",
            "Collecting Werkzeug==0.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/57/92a497e38161ce40606c27a86759c6b92dd34fcdb33f64171ec559257c02/Werkzeug-0.15.4-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 67.2MB/s \n",
            "\u001b[?25hCollecting widgetsnbextension==3.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/81/35789a3952afb48238289171728072d26d6e76649ddc8b3588657a2d78c1/widgetsnbextension-3.4.2-py2.py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython==7.5.0->-r requirements.txt (line 15)) (46.3.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1->-r requirements.txt (line 65)) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 67)) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 67)) (3.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 67)) (0.2.0)\n",
            "Building wheels for collected packages: absl-py, gast, html5lib, prometheus-client, pyrsistent, PyYAML, tornado\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.7.1-cp36-none-any.whl size=117848 sha256=0592b3524317141e408301b63333fba7d3f18c3acd0b8094dd6cd9d8352e5ecc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=b49b6413bd8a04ce01849972fb9237fb2625ef4b043ff37c355623f491e476f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=057d3bd85adabf0e32cfc37533353df9e1860415229b36e7717dc01137240794\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.6.0-cp36-none-any.whl size=39584 sha256=e4b61682f4c0ee97c4c65c571b721348b3a2481a6277745ee44a542029e906de\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/04/b8/3709c73e7453f311ebd46ad581b89642543213f995e2659b9e\n",
            "  Building wheel for pyrsistent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrsistent: filename=pyrsistent-0.15.2-cp36-cp36m-linux_x86_64.whl size=97505 sha256=5691d766553a6794e9611a6c0ba84ca44d5802e7961956c4df717a7042065b37\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/b9/15/c8c6a1e095a370e8c3273e65a5c982e5cf355dde16d77502f5\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.1-cp36-cp36m-linux_x86_64.whl size=44074 sha256=fca6d4a750813dc24981dd98d4eef209027e615cdb180d598b522c62c60799f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.0.2-cp36-cp36m-linux_x86_64.whl size=422924 sha256=f085788d3c95b5c38587447c9cf4b0b23c7e7280317542c0255f567fc8dc76a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/7e/7a/5e02e60dc329aef32ecf70e0425319ee7e2198c3a7cf98b4a2\n",
            "Successfully built absl-py gast html5lib prometheus-client pyrsistent PyYAML tornado\n",
            "\u001b[31mERROR: tensorflow 1.15.2 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.2 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.2 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.2 has requirement scipy>=1.3.1, but you'll have scipy 1.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.5.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement notebook~=5.2.0, but you'll have notebook 5.7.8 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 1.15.2 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 1.15.2 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: absl-py, astor, attrs, bleach, decorator, gast, grpcio, numpy, h5py, html5lib, Pygments, parso, jedi, wcwidth, prompt-toolkit, traitlets, pexpect, ipython, jupyter-core, pyzmq, tornado, python-dateutil, jupyter-client, ipykernel, Jinja2, pyrsistent, jsonschema, nbformat, testpath, nbconvert, terminado, prometheus-client, notebook, widgetsnbextension, ipywidgets, joblib, jupyter-console, jupyterlab-server, jupyterlab, scipy, PyYAML, Keras-Preprocessing, Keras, kiwisolver, Markdown, pyparsing, matplotlib, mock, nibabel, nilearn, pytz, pandas, protobuf, pydot, qtconsole, scikit-learn, Werkzeug, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: absl-py 0.9.0\n",
            "    Uninstalling absl-py-0.9.0:\n",
            "      Successfully uninstalled absl-py-0.9.0\n",
            "  Found existing installation: astor 0.8.1\n",
            "    Uninstalling astor-0.8.1:\n",
            "      Successfully uninstalled astor-0.8.1\n",
            "  Found existing installation: attrs 19.3.0\n",
            "    Uninstalling attrs-19.3.0:\n",
            "      Successfully uninstalled attrs-19.3.0\n",
            "  Found existing installation: bleach 3.1.5\n",
            "    Uninstalling bleach-3.1.5:\n",
            "      Successfully uninstalled bleach-3.1.5\n",
            "  Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: grpcio 1.28.1\n",
            "    Uninstalling grpcio-1.28.1:\n",
            "      Successfully uninstalled grpcio-1.28.1\n",
            "  Found existing installation: numpy 1.18.4\n",
            "    Uninstalling numpy-1.18.4:\n",
            "      Successfully uninstalled numpy-1.18.4\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: Pygments 2.1.3\n",
            "    Uninstalling Pygments-2.1.3:\n",
            "      Successfully uninstalled Pygments-2.1.3\n",
            "  Found existing installation: parso 0.7.0\n",
            "    Uninstalling parso-0.7.0:\n",
            "      Successfully uninstalled parso-0.7.0\n",
            "  Found existing installation: jedi 0.17.0\n",
            "    Uninstalling jedi-0.17.0:\n",
            "      Successfully uninstalled jedi-0.17.0\n",
            "  Found existing installation: wcwidth 0.1.9\n",
            "    Uninstalling wcwidth-0.1.9:\n",
            "      Successfully uninstalled wcwidth-0.1.9\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: traitlets 4.3.3\n",
            "    Uninstalling traitlets-4.3.3:\n",
            "      Successfully uninstalled traitlets-4.3.3\n",
            "  Found existing installation: pexpect 4.8.0\n",
            "    Uninstalling pexpect-4.8.0:\n",
            "      Successfully uninstalled pexpect-4.8.0\n",
            "  Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Found existing installation: jupyter-core 4.6.3\n",
            "    Uninstalling jupyter-core-4.6.3:\n",
            "      Successfully uninstalled jupyter-core-4.6.3\n",
            "  Found existing installation: pyzmq 19.0.1\n",
            "    Uninstalling pyzmq-19.0.1:\n",
            "      Successfully uninstalled pyzmq-19.0.1\n",
            "  Found existing installation: tornado 4.5.3\n",
            "    Uninstalling tornado-4.5.3:\n",
            "      Successfully uninstalled tornado-4.5.3\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Found existing installation: jupyter-client 5.3.4\n",
            "    Uninstalling jupyter-client-5.3.4:\n",
            "      Successfully uninstalled jupyter-client-5.3.4\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "  Found existing installation: Jinja2 2.11.2\n",
            "    Uninstalling Jinja2-2.11.2:\n",
            "      Successfully uninstalled Jinja2-2.11.2\n",
            "  Found existing installation: pyrsistent 0.16.0\n",
            "    Uninstalling pyrsistent-0.16.0:\n",
            "      Successfully uninstalled pyrsistent-0.16.0\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Found existing installation: nbformat 5.0.6\n",
            "    Uninstalling nbformat-5.0.6:\n",
            "      Successfully uninstalled nbformat-5.0.6\n",
            "  Found existing installation: testpath 0.4.4\n",
            "    Uninstalling testpath-0.4.4:\n",
            "      Successfully uninstalled testpath-0.4.4\n",
            "  Found existing installation: nbconvert 5.6.1\n",
            "    Uninstalling nbconvert-5.6.1:\n",
            "      Successfully uninstalled nbconvert-5.6.1\n",
            "  Found existing installation: terminado 0.8.3\n",
            "    Uninstalling terminado-0.8.3:\n",
            "      Successfully uninstalled terminado-0.8.3\n",
            "  Found existing installation: prometheus-client 0.7.1\n",
            "    Uninstalling prometheus-client-0.7.1:\n",
            "      Successfully uninstalled prometheus-client-0.7.1\n",
            "  Found existing installation: notebook 5.2.2\n",
            "    Uninstalling notebook-5.2.2:\n",
            "      Successfully uninstalled notebook-5.2.2\n",
            "  Found existing installation: widgetsnbextension 3.5.1\n",
            "    Uninstalling widgetsnbextension-3.5.1:\n",
            "      Successfully uninstalled widgetsnbextension-3.5.1\n",
            "  Found existing installation: ipywidgets 7.5.1\n",
            "    Uninstalling ipywidgets-7.5.1:\n",
            "      Successfully uninstalled ipywidgets-7.5.1\n",
            "  Found existing installation: joblib 0.14.1\n",
            "    Uninstalling joblib-0.14.1:\n",
            "      Successfully uninstalled joblib-0.14.1\n",
            "  Found existing installation: jupyter-console 5.2.0\n",
            "    Uninstalling jupyter-console-5.2.0:\n",
            "      Successfully uninstalled jupyter-console-5.2.0\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: Keras-Preprocessing 1.1.0\n",
            "    Uninstalling Keras-Preprocessing-1.1.0:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "  Found existing installation: kiwisolver 1.2.0\n",
            "    Uninstalling kiwisolver-1.2.0:\n",
            "      Successfully uninstalled kiwisolver-1.2.0\n",
            "  Found existing installation: Markdown 3.2.1\n",
            "    Uninstalling Markdown-3.2.1:\n",
            "      Successfully uninstalled Markdown-3.2.1\n",
            "  Found existing installation: pyparsing 2.4.7\n",
            "    Uninstalling pyparsing-2.4.7:\n",
            "      Successfully uninstalled pyparsing-2.4.7\n",
            "  Found existing installation: matplotlib 3.2.1\n",
            "    Uninstalling matplotlib-3.2.1:\n",
            "      Successfully uninstalled matplotlib-3.2.1\n",
            "  Found existing installation: nibabel 3.0.2\n",
            "    Uninstalling nibabel-3.0.2:\n",
            "      Successfully uninstalled nibabel-3.0.2\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.0.3\n",
            "    Uninstalling pandas-1.0.3:\n",
            "      Successfully uninstalled pandas-1.0.3\n",
            "  Found existing installation: protobuf 3.10.0\n",
            "    Uninstalling protobuf-3.10.0:\n",
            "      Successfully uninstalled protobuf-3.10.0\n",
            "  Found existing installation: pydot 1.3.0\n",
            "    Uninstalling pydot-1.3.0:\n",
            "      Successfully uninstalled pydot-1.3.0\n",
            "  Found existing installation: qtconsole 4.7.4\n",
            "    Uninstalling qtconsole-4.7.4:\n",
            "      Successfully uninstalled qtconsole-4.7.4\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed Jinja2-2.10.1 Keras-2.2.4 Keras-Preprocessing-1.0.9 Markdown-3.1.1 PyYAML-5.1 Pygments-2.4.2 Werkzeug-0.15.4 absl-py-0.7.1 astor-0.8.0 attrs-19.1.0 bleach-3.1.4 decorator-4.4.0 gast-0.2.2 grpcio-1.21.1 h5py-2.9.0 html5lib-0.9999999 ipykernel-5.1.1 ipython-7.5.0 ipywidgets-7.4.2 jedi-0.13.3 joblib-0.13.2 jsonschema-3.0.1 jupyter-client-5.2.4 jupyter-console-6.0.0 jupyter-core-4.4.0 jupyterlab-0.35.6 jupyterlab-server-0.2.0 kiwisolver-1.1.0 matplotlib-3.0.3 mock-3.0.5 nbconvert-5.5.0 nbformat-4.4.0 nibabel-2.4.1 nilearn-0.5.2 notebook-5.7.8 numpy-1.16.4 pandas-0.24.2 parso-0.4.0 pexpect-4.7.0 prometheus-client-0.6.0 prompt-toolkit-2.0.9 protobuf-3.8.0 pydot-1.4.1 pyparsing-2.4.0 pyrsistent-0.15.2 python-dateutil-2.8.0 pytz-2019.1 pyzmq-18.0.1 qtconsole-4.5.1 scikit-learn-0.21.2 scipy-1.3.0 tensorboard-2.2.1 tensorflow-estimator-2.2.0 tensorflow-gpu-1.15.2 terminado-0.8.2 testpath-0.4.2 tornado-6.0.2 traitlets-4.3.2 wcwidth-0.1.7 widgetsnbextension-3.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "absl",
                  "astor",
                  "dateutil",
                  "decorator",
                  "gast",
                  "google",
                  "grpc",
                  "h5py",
                  "ipykernel",
                  "ipywidgets",
                  "jupyter_client",
                  "jupyter_core",
                  "keras_preprocessing",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas",
                  "pexpect",
                  "prompt_toolkit",
                  "pygments",
                  "pyparsing",
                  "pytz",
                  "scipy",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator",
                  "tornado",
                  "traitlets",
                  "wcwidth",
                  "yaml",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n7AEI4vMAKA",
        "colab_type": "text"
      },
      "source": [
        "#Step 0: Load & Setup the Data  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRRE1hYSL_ol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffff470e-ffe3-47d2-9a26-993acd25c730"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as ran\n",
        "import matplotlib\n",
        "\n",
        "#Deep learning package\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv3D, MaxPooling3D, AveragePooling3D, Input, ZeroPadding3D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import initializers\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, Adadelta, RMSprop, Adamax, Nadam, SGD  #using Adam in this model..just showing others\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68yIKIlpOXYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "bed804d1-10c0-40f2-88c5-83a8d16b1bcc"
      },
      "source": [
        "#neuroimaging specific python packages\n",
        "import nilearn\n",
        "from nilearn import plotting\n",
        "import nibabel as nib"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMWxIwuzO9uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "46e0be97-c806-4845-d118-0725d889445f"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/saigerutherford/anatomically_defined_CNNs/master/data/pheno_file.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-16 22:36:57--  https://raw.githubusercontent.com/saigerutherford/anatomically_defined_CNNs/master/data/pheno_file.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51946 (51K) [text/plain]\n",
            "Saving to: ‘pheno_file.csv’\n",
            "\n",
            "\rpheno_file.csv        0%[                    ]       0  --.-KB/s               \rpheno_file.csv      100%[===================>]  50.73K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-05-16 22:36:57 (29.2 MB/s) - ‘pheno_file.csv’ saved [51946/51946]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUrGuUO_PVal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d35a3f30-c861-4403-83b1-4d4bd5030f60"
      },
      "source": [
        "#Read in the csv file with subject info\n",
        "pheno= pd.read_csv('/content/pheno_file.csv')\n",
        "print(pheno.head(10))\n",
        "pheno['Age'].describe()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Subject           EID  Sex  ...  EHQ_Total  Commercial_Use Full_Pheno\n",
            "0  sub-NDARAA075AMK  NDARAA075AMK    1  ...      65.57              No        Yes\n",
            "1  sub-NDARAA536PTU  NDARAA536PTU    0  ...     -86.71              No        Yes\n",
            "2  sub-NDARAA948VFH  NDARAA948VFH    1  ...      90.05             Yes         No\n",
            "3  sub-NDARAC349YUC  NDARAC349YUC    1  ...      86.71             Yes        Yes\n",
            "4  sub-NDARAC350BZ0  NDARAC350BZ0    0  ...      66.77             Yes         No\n",
            "5  sub-NDARAC350XUM  NDARAC350XUM    0  ...      46.69             Yes         No\n",
            "6  sub-NDARAC853DTE  NDARAC853DTE    0  ...      83.38             Yes        Yes\n",
            "7  sub-NDARAC857HDB  NDARAC857HDB    0  ...      53.36             Yes         No\n",
            "8  sub-NDARAC904DMU  NDARAC904DMU    1  ...      71.17             Yes        Yes\n",
            "9  sub-NDARAD224CRB  NDARAD224CRB    0  ...      56.70             Yes         No\n",
            "\n",
            "[10 rows x 7 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    906.000000\n",
              "mean      10.824074\n",
              "std        3.558937\n",
              "min        5.036048\n",
              "25%        8.039898\n",
              "50%       10.031599\n",
              "75%       13.057266\n",
              "max       21.816563\n",
              "Name: Age, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbqFMCE-my6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "8e18e6dd-b762-4ce2-febb-146a11a10f3c"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.hist(pheno['Age'], bins=15)\n",
        "plt.show"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8jGwF3fovaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bb8717e9-b7cd-4561-d4fc-b90ed0d4482a"
      },
      "source": [
        "!wget -nc https://storage.googleapis.com/ohbm-dl-lindsay-data/OHBM_DL_SR_data.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-16 22:38:56--  https://storage.googleapis.com/ohbm-dl-lindsay-data/OHBM_DL_SR_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 2404:6800:4003:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 265718959 (253M) [application/zip]\n",
            "Saving to: ‘OHBM_DL_SR_data.zip’\n",
            "\n",
            "OHBM_DL_SR_data.zip 100%[===================>] 253.41M  29.4MB/s    in 8.6s    \n",
            "\n",
            "2020-05-16 22:39:05 (29.4 MB/s) - ‘OHBM_DL_SR_data.zip’ saved [265718959/265718959]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMyQtRUdpASN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "abe47281-735c-4fcc-aaa9-20f2a1c9ae00"
      },
      "source": [
        "!unzip -uo OHBM_DL_SR_data.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  OHBM_DL_SR_data.zip\n",
            "  inflating: OHBM_DL_data/downsampled_test_labels.npy  \n",
            "  inflating: OHBM_DL_data/savedmodels/metadata_batch20_epoch10.tsv  \n",
            "  inflating: OHBM_DL_data/downsampled_train_labels.npy  \n",
            "  inflating: OHBM_DL_data/savedmodels/best_weights_batch5epoch30.h5  \n",
            "  inflating: OHBM_DL_data/savedmodels/log_batch20epoch10.csv  \n",
            "  inflating: OHBM_DL_data/savedmodels/weights.20-12.44.hdf5  \n",
            "  inflating: OHBM_DL_data/savedmodels/best_weights_batch20epoch10.h5  \n",
            "  inflating: OHBM_DL_data/savedmodels/metadata_batch5_epoch30.tsv  \n",
            "  inflating: OHBM_DL_data/savedmodels/metadata_batch10_epoch20.tsv  \n",
            "  inflating: OHBM_DL_data/savedmodels/log_batch10epoch20.csv  \n",
            "  inflating: OHBM_DL_data/savedmodels/SavedModel_batch20_epoch10.h5  \n",
            "  inflating: OHBM_DL_data/savedmodels/SavedModel_batch10_epoch20.h5  \n",
            "  inflating: OHBM_DL_data/savedmodels/SavedModel_batch5_epoch30.h5  \n",
            "  inflating: OHBM_DL_data/savedmodels/TensorBoardLogs/events.out.tfevents.1559899998.freewill  \n",
            "  inflating: OHBM_DL_data/savedmodels/best_weights_batch10epoch20.h5  \n",
            "  inflating: OHBM_DL_data/savedmodels/TensorBoardLogs/events.out.tfevents.1559900982.freewill  \n",
            "  inflating: OHBM_DL_data/savedmodels/TensorBoardLogs/events.out.tfevents.1559901556.freewill  \n",
            "  inflating: OHBM_DL_data/downsampled_test.npy  \n",
            "  inflating: OHBM_DL_data/savedmodels/TensorBoardLogs/events.out.tfevents.1559899954.freewill  \n",
            "  inflating: OHBM_DL_data/downsampled_train.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpw70Ka8pHXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create root path for Colab\n",
        "root_path= '/content/OHBM_DL_data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR5YsJCBpNR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "255b0819-38c3-4fc6-ca79-eb261a3f461a"
      },
      "source": [
        "ls OHBM_DL_data"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downsampled_test_labels.npy  downsampled_train_labels.npy  \u001b[0m\u001b[01;34msavedmodels\u001b[0m/\n",
            "downsampled_test.npy         downsampled_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd7YYB_GpVwM",
        "colab_type": "text"
      },
      "source": [
        "#Load Data(already divided int train and test sets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC56P5jipaGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train= np.load(root_path + 'downsampled_train.npy')\n",
        "x_test= np.load(root_path + 'downsampled_test.npy')\n",
        "y_train= np.load(root_path + 'downsampled_train_labels.npy')\n",
        "y_test= np.load(root_path + 'downsampled_test_labels.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp5iOE7IqnzU",
        "colab_type": "text"
      },
      "source": [
        "#Check Input Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBhlev4Lqmws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df2c4ab6-0d08-4db4-8251-8b018829d95d"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(724, 48, 60, 46, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5RKQoAbq19p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "344deb1d-7570-4cad-9f63-9f9f6cf4e2f0"
      },
      "source": [
        "n_train= x_train.shape[0]\n",
        "n_test= x_test.shape[0]\n",
        "image_shape= x_train[0].shape\n",
        "print('Number of training examples =', n_train)\n",
        "print('Number of test examples =', n_test)\n",
        "print('Image data shape =', image_shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples = 724\n",
            "Number of test examples = 182\n",
            "Image data shape = (48, 60, 46, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXFySfehs33X",
        "colab_type": "text"
      },
      "source": [
        "#Step1: Model Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLqzNDJls8Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "a6b8e078-1c14-4bb9-c929-e7fa15465aec"
      },
      "source": [
        "#create o-ur CNN model\n",
        "from keras.layers import Flatten   #forgot to import in earlier cells\n",
        "\n",
        "model= Sequential()\n",
        "model.add(Conv3D(filters= 64, kernel_size=(3,3,3), activation= 'elu', strides= 1, padding= 'same',\n",
        "                 kernel_initializer= 'glorot_uniform',\n",
        "                 input_shape= image_shape))\n",
        "model.add(Conv3D(filters= 64, kernel_size=(3,3,3), activation='elu', strides= (1,1,1), padding= 'same'))\n",
        "model.add(Conv3D(filters= 64, kernel_size= (3,3,3), activation='elu', strides= (1,1,1), padding= 'same'))\n",
        "model.add(MaxPooling3D((2,2,2), strides= (2,2,2)))  #ppoling is also referred to as downasampling layer\n",
        "model.add(BatchNormalization())  #normalize the activations of the previous layer at each batch\n",
        "\n",
        "model.add(Conv3D(filters=32, kernel_size=(3,3,3), activation='elu', strides= (1,1,1), padding='same'))\n",
        "model.add(Conv3D(filters= 32, kernel_size=(3,3,3), activation= 'elu', strides= (1,1,1), padding= 'same'))\n",
        "model.add(MaxPooling3D((2,2,2), strides= (2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(filters= 16, kernel_size=(3,3,3), activation='elu', strides= (1,1,1), padding= 'same'))\n",
        "model.add(Conv3D(filters= 16, kernel_size=(3,3,3), activation='elu', strides= (1,1,1), padding= 'same'))\n",
        "model.add(MaxPooling3D((2,2,2), strides=(2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv3D(filters= 8, kernel_size= (3,3,3), activation='elu', strides= (1,1,1), padding= 'same'))\n",
        "model.add(Conv3D(filters= 8, kernel_size= (3,3,3), activation='elu', strides= (1,1,1), padding= 'same'))\n",
        "model.add(MaxPooling3D((2,2,2), strides= (2,2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(AveragePooling3D((2,2,2), strides= (2,2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu', name= 'features'))  #convert the output of convolutional part into 1D vector\n",
        "model.add(Dense(1))  #final output is a single number (Age in this model) \n",
        "model.summary()\n",
        "\n",
        "filename= 'best_weights.h5'\n",
        "filename2= 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_25 (Conv3D)           (None, 48, 60, 46, 64)    5248      \n",
            "_________________________________________________________________\n",
            "conv3d_26 (Conv3D)           (None, 48, 60, 46, 64)    110656    \n",
            "_________________________________________________________________\n",
            "conv3d_27 (Conv3D)           (None, 48, 60, 46, 64)    110656    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_11 (MaxPooling (None, 24, 30, 23, 64)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 24, 30, 23, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv3d_28 (Conv3D)           (None, 24, 30, 23, 32)    55328     \n",
            "_________________________________________________________________\n",
            "conv3d_29 (Conv3D)           (None, 24, 30, 23, 32)    27680     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_12 (MaxPooling (None, 12, 15, 11, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 12, 15, 11, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv3d_30 (Conv3D)           (None, 12, 15, 11, 16)    13840     \n",
            "_________________________________________________________________\n",
            "conv3d_31 (Conv3D)           (None, 12, 15, 11, 16)    6928      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_13 (MaxPooling (None, 6, 7, 5, 16)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 6, 7, 5, 16)       64        \n",
            "_________________________________________________________________\n",
            "conv3d_32 (Conv3D)           (None, 6, 7, 5, 8)        3464      \n",
            "_________________________________________________________________\n",
            "conv3d_33 (Conv3D)           (None, 6, 7, 5, 8)        1736      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_14 (MaxPooling (None, 3, 3, 2, 8)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 3, 3, 2, 8)        32        \n",
            "_________________________________________________________________\n",
            "average_pooling3d_2 (Average (None, 1, 1, 1, 8)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "features (Dense)             (None, 1024)              9216      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 346,257\n",
            "Trainable params: 346,017\n",
            "Non-trainable params: 240\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkvzfj1sxwUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoints= []\n",
        "\n",
        "if not os.path.exists('Results01/'):\n",
        "  os.makedirs('Results01/')\n",
        "\n",
        "checkpoints.append(ModelCheckpoint('Results01' + filename,\n",
        "                                   monitor= 'val_loss',\n",
        "                                   verbose= 1,\n",
        "                                   save_best_only= True,\n",
        "                                   save_weights_only= True,\n",
        "                                   mode= 'auto',\n",
        "                                   period= 1))\n",
        "\n",
        "checkpoints.append(ModelCheckpoint('Results01/' + filename2,\n",
        "                                   monitor= 'val_loss',\n",
        "                                   verbose= 1,\n",
        "                                   save_best_only= False,\n",
        "                                   save_weights_only= True,\n",
        "                                   mode= 'auto',\n",
        "                                   period= 20))\n",
        "\n",
        "checkpoints.append(TensorBoard(log_dir= 'Results01/TensorboardLogs',\n",
        "                               histogram_freq= 0,\n",
        "                               write_graph= True,\n",
        "                               write_images= False,\n",
        "                               embeddings_freq= 0,\n",
        "                               embeddings_layer_names= ['features'],\n",
        "                               embeddings_metadata= 'metadata.tsv'))\n",
        "\n",
        "#early stopping here is set that if the MSE in the validation set does not improve after 10 epochs, training stops\n",
        "checkpoints.append(EarlyStopping(monitor= 'val_loss', mode= 'auto', min_delta=0, patience= 10))\n",
        "checkpoints.append(ReduceLROnPlateau(monitor= 'val_loss', factor= 0.1, patience= 10, verbose=0, mode='auto', mi_delta= 0.0001,\n",
        "                                     cooldown= 0, min_lr= 0))\n",
        "checkpoints.append(CSVLogger('Results01/log.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foTyH-Gl0mUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "19fa175b-b276-4924-9eb1-3a099c7ffbeb"
      },
      "source": [
        "#compile our model\n",
        "model.compile(loss= 'mse',  #the objective that the model will try to miniimize, Mean Squared Error in this model \n",
        "              optimizer= 'adam',\n",
        "              metrics= ['mae'])  #add in any other metrics you want to use to show performance of the model such as accuracy if this was a classification problem"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0516 23:32:26.807458 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLIQMie81RR9",
        "colab_type": "text"
      },
      "source": [
        "# Step2: Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKu549cB1Qqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "8e5bcb48-a688-40a0-9327-4eb5b8bf2d92"
      },
      "source": [
        "#check available GPU's\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0516 23:34:00.030622 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0516 23:34:00.033770 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0516 23:34:00.038132 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0516 23:34:01.580378 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W0516 23:34:01.581392 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "W0516 23:34:01.872323 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAz8pMWW1qCJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "b9a6a85b-8483-40c2-cf1b-fd2ec7bbddea"
      },
      "source": [
        "NUM_EPOCHS= 10   #this defines for how many times the training will repeat in cycles\n",
        "BATCH_SIZE= 20    #the number of training exmaples in one forwaard/backward pass (or for 1 epoch)\n",
        "history1= model.fit(x_train, y_train,\n",
        "                    validation_split= 0.1,\n",
        "                    batch_size= BATCH_SIZE,\n",
        "                    epochs= NUM_EPOCHS,\n",
        "                    callbacks= checkpoints)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0516 23:35:53.188963 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0516 23:35:53.427055 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 651 samples, validate on 73 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 23:35:54.137706 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "W0516 23:35:54.139470 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "651/651 [==============================] - 67s 102ms/step - loss: 61.1841 - mean_absolute_error: 6.5634 - val_loss: 66.7337 - val_mean_absolute_error: 7.3057\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 66.73371, saving model to Results01best_weights.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 23:37:01.933632 139993318365056 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "651/651 [==============================] - 56s 85ms/step - loss: 13.1471 - mean_absolute_error: 2.9944 - val_loss: 87.5659 - val_mean_absolute_error: 8.6167\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 66.73371\n",
            "Epoch 3/10\n",
            "651/651 [==============================] - 56s 86ms/step - loss: 13.1161 - mean_absolute_error: 2.9522 - val_loss: 44.2804 - val_mean_absolute_error: 5.8497\n",
            "\n",
            "Epoch 00003: val_loss improved from 66.73371 to 44.28044, saving model to Results01best_weights.h5\n",
            "Epoch 4/10\n",
            "651/651 [==============================] - 56s 86ms/step - loss: 12.7431 - mean_absolute_error: 2.9250 - val_loss: 31.2903 - val_mean_absolute_error: 4.7842\n",
            "\n",
            "Epoch 00004: val_loss improved from 44.28044 to 31.29030, saving model to Results01best_weights.h5\n",
            "Epoch 5/10\n",
            "651/651 [==============================] - 56s 86ms/step - loss: 12.7626 - mean_absolute_error: 2.9389 - val_loss: 15.4925 - val_mean_absolute_error: 3.4209\n",
            "\n",
            "Epoch 00005: val_loss improved from 31.29030 to 15.49250, saving model to Results01best_weights.h5\n",
            "Epoch 6/10\n",
            "651/651 [==============================] - 56s 86ms/step - loss: 12.6711 - mean_absolute_error: 2.9263 - val_loss: 12.8159 - val_mean_absolute_error: 3.0108\n",
            "\n",
            "Epoch 00006: val_loss improved from 15.49250 to 12.81592, saving model to Results01best_weights.h5\n",
            "Epoch 7/10\n",
            "651/651 [==============================] - 56s 86ms/step - loss: 12.7180 - mean_absolute_error: 2.9069 - val_loss: 13.6206 - val_mean_absolute_error: 2.9099\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 12.81592\n",
            "Epoch 8/10\n",
            "651/651 [==============================] - 56s 86ms/step - loss: 12.8371 - mean_absolute_error: 2.9488 - val_loss: 17.3212 - val_mean_absolute_error: 3.6141\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 12.81592\n",
            "Epoch 9/10\n",
            "651/651 [==============================] - 56s 86ms/step - loss: 12.6411 - mean_absolute_error: 2.9177 - val_loss: 12.9715 - val_mean_absolute_error: 3.0430\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 12.81592\n",
            "Epoch 10/10\n",
            "651/651 [==============================] - 56s 86ms/step - loss: 12.6564 - mean_absolute_error: 2.9197 - val_loss: 23.8070 - val_mean_absolute_error: 3.7634\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 12.81592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7aAEZuU4Xd7",
        "colab_type": "text"
      },
      "source": [
        "#Step 3: Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiFg8ZhI4UO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a7d29aa9-1644-4e72-c684-21fcf375aa69"
      },
      "source": [
        "model.evaluate(x= x_test, y= y_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "182/182 [==============================] - 8s 42ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20.378042179149585, 3.275671505666041]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R61pGpEy4koU",
        "colab_type": "text"
      },
      "source": [
        "#Step 4: Save Model\n",
        "1. the architecture of the model\n",
        "2. the weights of the model\n",
        "3. the training configuration (loss optimizer)\n",
        "4. the state of the optimizer, allowing to reaume training exactly where you left off"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NB_kvy64nZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Results01/SavedModel_Batch-20Epochs-10.h5')  #always change this name when re-training (if you haven't change directories) so you don't overwrite it!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV5FWzZx5QeQ",
        "colab_type": "text"
      },
      "source": [
        "#Step 5: Load Pre-Trained Model, Compile, Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FboNjjut5P_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "pretrain_model_b10e20= load_model(root_path + 'savedmodels/SavedModel_batch10_epoch20.h5')\n",
        "pretrain_model_b5e30= load_model(root_path + 'savedmodels/SavedModel_batch5_epoch30.h5')\n",
        "\n",
        "#pretrain_model_b10e20.summary()\n",
        "#pretrain_model.b5e30.summary()\n",
        "\n",
        "pretrain_model_b10e20.compile(loss= 'mse',\n",
        "                              optimizer= 'adam',\n",
        "                              metrics= ['mae', 'acc'])\n",
        "pretrain_model_b5e30.compile(loss= 'mse',\n",
        "                             optimizer= 'adam',\n",
        "                             metrics= ['mae','acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U753N77H6sJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "88903761-67f9-468e-a948-f50f91b05314"
      },
      "source": [
        "#evaluate model\n",
        "pretrain_model_b10e20.evaluate(x= x_test, y= y_test)\n",
        "pretrain_model_b5e30.evaluate(x= x_test, y= y_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "182/182 [==============================] - 6s 32ms/step\n",
            "182/182 [==============================] - 5s 29ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18.971879613268506, 3.136493452302702, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}